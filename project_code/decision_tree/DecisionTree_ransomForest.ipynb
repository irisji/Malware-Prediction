{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,Normalizer,PolynomialFeatures,MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, KFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score ,f1_score, ConfusionMatrixDisplay, make_scorer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class MyPredictor:\n",
    "    \n",
    "    with_eng = False\n",
    "    with_clean_rows = False\n",
    "    del_col_missing_rate = 1\n",
    "    \n",
    "    def __init__(self,with_eng, with_clean_rows, del_col_missing_rate):\n",
    "        \n",
    "        #self.df = df\n",
    "        self.with_eng = with_eng\n",
    "        self.with_clean_rows = with_clean_rows\n",
    "        self.del_col_missing_rate = del_col_missing_rate\n",
    "    \n",
    "\n",
    "        self.ignore_cols = ['HasDetections','MachineIdentifier','HasTpm','Firewall','Census_HasOpticalDiskDrive', 'Census_PrimaryDiskTotalCapacity','Census_IsSecureBootEnabled','Census_IsWIMBootEnabled','Census_IsTouchEnabled','EngineVersion1','EngineVersion2','AppVersion1','AvSigVersion4','AvSigVersion1','Census_OSVersion1','Census_OSVersion2','OsPlatformSubRelease']\n",
    "        self.enc_cols = []\n",
    "        self.std_cols = []\n",
    "        self.nrm_cols = []\n",
    "\n",
    "        self.categoric_cols = []\n",
    "        self.numeric_cols = []\n",
    "        self.others = []\n",
    "        self.identifier_cols = []\n",
    "\n",
    "        self.mode = {}\n",
    "\n",
    "    def info(self,df):\n",
    "        metaData = df.describe(include='all')\n",
    "\n",
    "        self.describe_df = pd.DataFrame()\n",
    "        self.describe_df['count'] = df.count()\n",
    "        self.describe_df['uniques'] = df.nunique()\n",
    "        self.describe_df['dtype'] = df.dtypes\n",
    "        self.describe_df['missing'] = 1 - df.count() /  len(df)\n",
    "        self.describe_df.sort_values(by='missing', ascending=False).head(20)\n",
    "        return self.describe_df\n",
    "        \n",
    " \n",
    "    def groupCols(self,x):\n",
    "        #print(self.ignore_cols)\n",
    "        if x.name in self.ignore_cols:\n",
    "            pass\n",
    "        elif x['missing'] > self.del_col_missing_rate:\n",
    "            self.ignore_cols.append(x.name)\n",
    "        elif str(x['dtype']).startswith('int') or str(x['dtype']).startswith('float') and not x.name.endswith('Identifier'):\n",
    "        #elif str(x['dtype']).startswith('int') or str(x['dtype']).startswith('float'):\n",
    "            self.numeric_cols.append(x.name)\n",
    "        elif str(x.name).endswith('Identifier'):\n",
    "            self.identifier_cols.append(x.name)\n",
    "        elif x['uniques'] <30:\n",
    "            self.categoric_cols.append(x.name)\n",
    "\n",
    "        else:\n",
    "            self.others.append(x.name)\n",
    "    \n",
    "    def preClean(self,df):\n",
    "        # delete rows: delete row with 80% missing x value and no y value\n",
    "        df= df.copy()\n",
    "        df.dropna(thresh = len(df.columns.tolist())*0.8, inplace = True)\n",
    "        df.reset_index(drop = True, inplace =True)\n",
    "        df.dropna(subset =['HasDetections'], inplace = True)\n",
    "        df.reset_index(drop = True, inplace =True)\n",
    "        return df\n",
    "    \n",
    "    def splitOsBuildLab(self,x):\n",
    "        y = str(x).split('.')\n",
    "        try:\n",
    "            y = y[2]\n",
    "        except:\n",
    "            return''\n",
    "        return y   \n",
    "    \n",
    "    def groupChassis(self,x):\n",
    "        if str(x).lower()=='':\n",
    "            return ''\n",
    "        elif ('desktop' or 'pc') in str(x).lower():\n",
    "            return 'desktop'\n",
    "        elif ('notebook'or 'laptop' or 'tablet') in str(x).lower():\n",
    "            return 'notebook'\n",
    "        elif ('portable'or 'handheld') in str(x).lower():\n",
    "            return 'portable'\n",
    "        elif 'allinone'in str(x).lower():\n",
    "            return 'allInOne'\n",
    "        elif 'tower'in str(x).lower():\n",
    "            return 'tower'\n",
    "        elif 'convertible'in str(x).lower():\n",
    "            return 'convertible'\n",
    "        elif 'detachable'in str(x).lower():\n",
    "            return 'detachable'\n",
    "        elif 'spacesaving'in str(x).lower():\n",
    "            return 'spaceSaving'\n",
    "        elif 'chassis'in str(x).lower():\n",
    "            return 'chassis'\n",
    "        elif 'box'in str(x).lower():\n",
    "            return 'box'\n",
    "        elif 'unknown'in str(x).lower():\n",
    "            return ''\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    \n",
    "    def groupBattery(self,x):\n",
    "        if str(x).lower().strip()=='':\n",
    "            return ''\n",
    "        elif ('liio' or 'lion' or 'li-i' or 'ithi') in str(x).lower().strip():\n",
    "            return 'lithium-ion'\n",
    "        elif 'lip' in str(x).lower().strip():\n",
    "            return 'Lithium_polymer'\n",
    "        elif 'nimh' in str(x).lower().strip():\n",
    "            return 'Nickelâ€“metal_hydride'\n",
    "        elif ('nan' or 'unk' )in str(x).lower().strip():\n",
    "            return ''\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def osGroup(self,x):\n",
    "        \n",
    "        if str(x) == '':\n",
    "            return ''\n",
    "        if 'professional' in str(x).lower():\n",
    "            return 'professional'\n",
    "        elif 'core' in str(x).lower():\n",
    "            return 'core'\n",
    "        elif 'server' in str(x).lower():\n",
    "            return 'server'\n",
    "        elif 'cloud' in str(x).lower():\n",
    "            return 'cloud'\n",
    "        elif 'enterprise' in str(x).lower():\n",
    "            return 'enterprise'\n",
    "        elif 'education' in str(x).lower():\n",
    "            return 'education'\n",
    "        elif 'ultimate' in str(x).lower():\n",
    "            return 'ultimate'\n",
    "        elif 'unlicensed' in str(x).lower():\n",
    "            return 'unlicensed'\n",
    "        elif 'workstation' in str(x).lower():\n",
    "            return 'workstation'\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def featureEng(self,df):\n",
    "        df = df.copy()\n",
    "        cols_list = df.columns.tolist()\n",
    "        for i, x in enumerate(cols_list):\n",
    "            if str(x).endswith('Version'):\n",
    "                self.ignore_cols.append(x)\n",
    "                #print('version',x,df[x].isnull().sum())\n",
    "                _df = pd.DataFrame(np.array(df[x].str.split('.').tolist()))\n",
    "  \n",
    "                for i in range(4):\n",
    "                    df[x+str(i+1)]=_df[i].astype('int64')\n",
    "            \n",
    "       \n",
    "    \n",
    "        df['OsBuildLab1'] = df['OsBuildLab'].apply(lambda x: self.splitOsBuildLab(x))\n",
    "        \n",
    "        df['Census_ChassisTypeName1']=df['Census_ChassisTypeName'].apply(lambda x: self.groupChassis(x))\n",
    "\n",
    "        df['Census_InternalBatteryType1']=df['Census_InternalBatteryType'].apply(lambda x: self.groupBattery(x))\n",
    "        \n",
    "        df['Census_OSEdition1']=df['Census_OSEdition'].apply(lambda x: self.osGroup(x))\n",
    "        df['Census_OSSkuName1']=df['Census_OSSkuName'].apply(lambda x: self.osGroup(x))\n",
    "        self.ignore_cols.extend(['OsBuildLab','Census_ChassisTypeName','Census_InternalBatteryType','Census_OSEdition','Census_OSSkuName'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "        \n",
    "    def fit_preprocessing(self,df):\n",
    "        df = df.copy()\n",
    "        \n",
    "        if self.with_eng:\n",
    "            print('eng')\n",
    "            df = self.featureEng(df)\n",
    "            \n",
    "        # delete rows\n",
    "        if self.with_clean_rows:\n",
    "            print('clean_rows')\n",
    "            df = self.preClean(df)\n",
    "        \n",
    "        #group columns\n",
    "        self.describe_df = self.info(df)\n",
    "        self.describe_df.apply(lambda x: self.groupCols(x), axis=1)\n",
    "            \n",
    "        # prepare columns for encoding\n",
    "        self.enc_cols = list(set(self.categoric_cols +self.enc_cols)-set(self.numeric_cols + self.std_cols) -set(self.nrm_cols) - set(self.ignore_cols))\n",
    "        self.std_cols = list(set(self.numeric_cols + self.std_cols) -set(self.nrm_cols) -set(self.categoric_cols +self.enc_cols) - set(self.ignore_cols))\n",
    "        if self.nrm_cols:\n",
    "            print('precol-nrm-true')\n",
    "            self.nrm_cols = list(set(self.nrm_cols) - set(self.categoric_cols+self.enc_cols) -set(self.numeric_cols + self.std_cols) - set(self.ignore_cols))\n",
    "       \n",
    "        # method1 cat <= mode, num <= median\n",
    "        for name in self.enc_cols:\n",
    "            self.mode[name] = df[name].mode(dropna = True)[0]\n",
    "        for name in self.std_cols:\n",
    "            self.mode[name] = df[name].mean()\n",
    "        for name in self.identifier_cols:\n",
    "            self.mode[name] = df[name].mode(dropna = True)[0]\n",
    "        if self.nrm_cols:\n",
    "            print('mode-nrm-true')\n",
    "            for name in self.nrm_cols:\n",
    "                self.mode[name] = df[name].menn()\n",
    "\n",
    "        '''\n",
    "        #medthod2 all <= mode\n",
    "        self.mode = {i: df[i].mode(dropna = True)[0] for i in df.columns.tolist()}\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        print('e',self.enc_cols)\n",
    "        print('s',self.std_cols)\n",
    "        print('n',self.nrm_cols)\n",
    "        print('i',self.identifier_cols)\n",
    "        print('ig',self.ignore_cols)\n",
    "        return df[self.enc_cols+self.std_cols+self.nrm_cols+self.identifier_cols], df['HasDetections']\n",
    "    \n",
    "    \n",
    "    def le_fit_transform(self,df):\n",
    "        df = df.copy()\n",
    "        self.le = LabelEncoder()\n",
    "\n",
    "        df[self.enc_cols] = df[self.enc_cols].fillna(self.mode).apply(self.le.fit_transform)\n",
    "        df[self.std_cols]=df[self.std_cols].fillna(self.mode).values\n",
    "        df[self.identifier_cols]=df[self.identifier_cols].fillna(self.mode).values\n",
    "        return df.values\n",
    "        \n",
    "\n",
    "    def fit_transformer(self,df):\n",
    "        self.enc = OneHotEncoder(handle_unknown='ignore',sparse = False)\n",
    "        self.enc.fit(df[self.enc_cols].fillna(self.mode).values)\n",
    "    \n",
    "    \n",
    "    def fit_model(self,df): \n",
    "        # Transform\n",
    "        X = self.transform(df)\n",
    "        # Fit model\n",
    "        self.linear_model = LogisticRegression()\n",
    "        self.linear_model.fit(X, df['HasDetections'])\n",
    "        \n",
    "   \n",
    "    def transform(self,df):\n",
    "        # transform columns\n",
    "        X1 = self.enc.transform(df[self.enc_cols].fillna(self.mode).values)\n",
    "        X2 = df[self.std_cols].fillna(self.mode).values\n",
    "        X4 = df[self.identifier_cols].fillna(self.mode).values\n",
    "        if self.nrm_cols:\n",
    "            print('transf-nrm')\n",
    "            X3 = self.nrm.transform(df[self.nrm_cols].fillna(self.mode).values)\n",
    "            return np.hstack((X1,X2,X3,X4))\n",
    "        else:\n",
    "            return np.hstack((X1,X2,X4))\n",
    "    \n",
    "    def predict(self,df):\n",
    "        df= df.copy()\n",
    "        if self.with_eng:\n",
    "            print('predi-eng')\n",
    "            df = self.featureEng(df) \n",
    "            \n",
    "        # delete rows\n",
    "        if self.with_clean_rows:\n",
    "            print('predi-clean-rows')\n",
    "            df = self.preClean(df)\n",
    "    \n",
    "        X = self.transform(df)\n",
    "        y_p_linear = self.linear_model.predict(X)\n",
    "        y_t_linear = df['HasDetections']\n",
    "        return y_p_linear, y_t_linear\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng\n",
      "split 0.076 leaf 0.001\n",
      "avg_train_f1_score: 0.6253384248876515\n",
      "avg_test_f1_score: 0.623604987137682\n",
      "split 0.076 leaf 0.0011\n",
      "avg_train_f1_score: 0.6253384248876515\n",
      "avg_test_f1_score: 0.623604987137682\n",
      "split 0.076 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6253384248876515\n",
      "avg_test_f1_score: 0.623604987137682\n",
      "split 0.076 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6253384248876515\n",
      "avg_test_f1_score: 0.623604987137682\n",
      "split 0.076 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6253079245463737\n",
      "avg_test_f1_score: 0.623568724957573\n",
      "split 0.076 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6253079245463737\n",
      "avg_test_f1_score: 0.623568724957573\n",
      "split 0.076 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6253079245463737\n",
      "avg_test_f1_score: 0.623568724957573\n",
      "split 0.076 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6253079245463737\n",
      "avg_test_f1_score: 0.623568724957573\n",
      "split 0.076 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6253079245463737\n",
      "avg_test_f1_score: 0.623568724957573\n",
      "split 0.076 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6251721548365915\n",
      "avg_test_f1_score: 0.6234545983682747\n",
      "split 0.0762 leaf 0.001\n",
      "avg_train_f1_score: 0.6253384248876515\n",
      "avg_test_f1_score: 0.623604987137682\n",
      "split 0.0762 leaf 0.0011\n",
      "avg_train_f1_score: 0.6253384248876515\n",
      "avg_test_f1_score: 0.623604987137682\n",
      "split 0.0762 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6253384248876515\n",
      "avg_test_f1_score: 0.623604987137682\n",
      "split 0.0762 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6253384248876515\n",
      "avg_test_f1_score: 0.623604987137682\n",
      "split 0.0762 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6253079245463737\n",
      "avg_test_f1_score: 0.623568724957573\n",
      "split 0.0762 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6253079245463737\n",
      "avg_test_f1_score: 0.623568724957573\n",
      "split 0.0762 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6253079245463737\n",
      "avg_test_f1_score: 0.623568724957573\n",
      "split 0.0762 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6253079245463737\n",
      "avg_test_f1_score: 0.623568724957573\n",
      "split 0.0762 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6253079245463737\n",
      "avg_test_f1_score: 0.623568724957573\n",
      "split 0.0762 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6251721548365915\n",
      "avg_test_f1_score: 0.6234545983682747\n",
      "split 0.07640000000000001 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07640000000000001 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07640000000000001 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07640000000000001 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07640000000000001 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07640000000000001 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07640000000000001 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07640000000000001 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07640000000000001 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07640000000000001 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07660000000000002 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07660000000000002 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07660000000000002 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07660000000000002 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07660000000000002 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07660000000000002 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07660000000000002 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07660000000000002 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07660000000000002 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07660000000000002 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07680000000000002 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07680000000000002 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07680000000000002 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07680000000000002 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07680000000000002 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07680000000000002 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07680000000000002 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07680000000000002 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07680000000000002 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07680000000000002 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07700000000000003 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07700000000000003 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07700000000000003 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07700000000000003 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07700000000000003 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07700000000000003 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07700000000000003 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07700000000000003 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07700000000000003 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07700000000000003 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07720000000000003 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07720000000000003 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07720000000000003 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07720000000000003 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07720000000000003 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07720000000000003 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07720000000000003 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0.07720000000000003 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07720000000000003 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07720000000000003 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07740000000000004 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07740000000000004 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07740000000000004 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07740000000000004 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07740000000000004 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07740000000000004 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07740000000000004 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07740000000000004 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07740000000000004 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07740000000000004 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07760000000000004 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07760000000000004 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07760000000000004 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07760000000000004 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07760000000000004 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07760000000000004 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07760000000000004 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07760000000000004 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07760000000000004 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07760000000000004 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07780000000000005 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07780000000000005 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07780000000000005 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07780000000000005 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07780000000000005 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07780000000000005 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07780000000000005 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07780000000000005 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07780000000000005 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07780000000000005 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07800000000000006 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07800000000000006 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07800000000000006 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07800000000000006 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07800000000000006 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07800000000000006 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07800000000000006 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07800000000000006 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07800000000000006 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07800000000000006 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07820000000000006 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07820000000000006 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07820000000000006 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07820000000000006 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07820000000000006 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07820000000000006 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07820000000000006 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07820000000000006 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07820000000000006 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07820000000000006 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07840000000000007 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07840000000000007 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07840000000000007 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07840000000000007 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07840000000000007 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07840000000000007 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07840000000000007 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07840000000000007 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07840000000000007 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07840000000000007 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07860000000000007 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07860000000000007 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0.07860000000000007 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07860000000000007 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07860000000000007 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07860000000000007 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07860000000000007 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07860000000000007 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07860000000000007 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07860000000000007 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07880000000000008 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07880000000000008 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07880000000000008 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07880000000000008 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07880000000000008 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07880000000000008 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07880000000000008 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07880000000000008 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07880000000000008 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07880000000000008 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n",
      "split 0.07900000000000008 leaf 0.001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07900000000000008 leaf 0.0011\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07900000000000008 leaf 0.0012000000000000001\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07900000000000008 leaf 0.0013000000000000002\n",
      "avg_train_f1_score: 0.6255228740617105\n",
      "avg_test_f1_score: 0.6238693866472499\n",
      "split 0.07900000000000008 leaf 0.0014000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07900000000000008 leaf 0.0015000000000000002\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07900000000000008 leaf 0.0016000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07900000000000008 leaf 0.0017000000000000003\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07900000000000008 leaf 0.0018000000000000004\n",
      "avg_train_f1_score: 0.6254923737204328\n",
      "avg_test_f1_score: 0.6238331244671408\n",
      "split 0.07900000000000008 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n"
     ]
    }
   ],
   "source": [
    "# use the class predictor same as the one in LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df = pd.read_csv('train_small.csv')\n",
    "predictor = MyPredictor(True, False, 1)\n",
    "df_X, df_y = predictor.fit_preprocessing(df)\n",
    "predictor.fit_transformer(df_X)\n",
    "\n",
    "X = predictor.transform(df_X)\n",
    "y = df_y\n",
    "\n",
    "\n",
    "\n",
    "min_samples_split = np.arange(0.076,0.079,0.0002)\n",
    "min_samples_leaf = np.arange(0.001,0.002,0.0001)\n",
    "\n",
    "for split in min_samples_split:\n",
    "    for leaf in min_samples_leaf:\n",
    "        kfold = KFold(n_splits = 5)\n",
    "        total_train = 0\n",
    "        total_test = 0\n",
    "        for train_index, test_index in kfold.split(X,y):\n",
    "            x_train = X[train_index]\n",
    "            y_train = y[train_index]\n",
    "            x_test = X[test_index]\n",
    "            y_test = y[test_index]\n",
    "\n",
    "            model = DecisionTreeClassifier(min_samples_split = split, min_samples_leaf =leaf)\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            total_train += f1_score(y_train,model.predict(x_train))\n",
    "            total_test += f1_score(y_test, model.predict(x_test))\n",
    "        print('split',split,'leaf',leaf)\n",
    "        print('avg_train_f1_score:',total_train/5)\n",
    "        print('avg_test_f1_score:',total_test/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0.01 leaf 0.01\n",
      "avg_train_f1_score: 0.6012814769676773\n",
      "avg_test_f1_score: 0.5984632402205338\n",
      "split 0.01 leaf 0.001\n",
      "avg_train_f1_score: 0.6107778994626955\n",
      "avg_test_f1_score: 0.6029508765938145\n",
      "split 0.01 leaf 0.0001\n",
      "avg_train_f1_score: 0.6160034321729476\n",
      "avg_test_f1_score: 0.6055461832949052\n",
      "split 0.001 leaf 0.01\n",
      "avg_train_f1_score: 0.6012814769676773\n",
      "avg_test_f1_score: 0.5984632402205338\n",
      "split 0.001 leaf 0.001\n",
      "avg_train_f1_score: 0.6239396157417925\n",
      "avg_test_f1_score: 0.6030632582467278\n",
      "split 0.001 leaf 0.0001\n",
      "avg_train_f1_score: 0.6525988251504694\n",
      "avg_test_f1_score: 0.5946107712331429\n",
      "split 0.0001 leaf 0.01\n",
      "avg_train_f1_score: 0.6012814769676773\n",
      "avg_test_f1_score: 0.5984632402205338\n",
      "split 0.0001 leaf 0.001\n",
      "avg_train_f1_score: 0.6239396157417925\n",
      "avg_test_f1_score: 0.6030632582467278\n",
      "split 0.0001 leaf 0.0001\n",
      "avg_train_f1_score: 0.6974453886135452\n",
      "avg_test_f1_score: 0.5788220319851695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "df = pd.read_csv('train_small.csv')\n",
    "predictor = MyPredictor(False, False, 1)\n",
    "df_X, df_y = predictor.fit_preprocessing(df)\n",
    "predictor.fit_transformer(df_X)\n",
    "\n",
    "X = predictor.transform(df_X)\n",
    "y = df_y\n",
    "\n",
    "\n",
    "\n",
    "min_samples_split = [0.01,0.001,0.0001]\n",
    "min_samples_leaf = [0.01,0.001,0.0001]\n",
    "\n",
    "for split in min_samples_split:\n",
    "    for leaf in min_samples_leaf:\n",
    "        kfold = KFold(n_splits = 5)\n",
    "        total_train = 0\n",
    "        total_test = 0\n",
    "        for train_index, test_index in kfold.split(X,y):\n",
    "            x_train = X[train_index]\n",
    "            y_train = y[train_index]\n",
    "            x_test = X[test_index]\n",
    "            y_test = y[test_index]\n",
    "\n",
    "            model = DecisionTreeClassifier(min_samples_split = split, min_samples_leaf =leaf)\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            total_train += f1_score(y_train,model.predict(x_train))\n",
    "            total_test += f1_score(y_test, model.predict(x_test))\n",
    "        print('split',split,'leaf',leaf)\n",
    "        print('avg_train_f1_score:',total_train/5)\n",
    "        print('avg_test_f1_score:',total_test/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-80849ec64377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rank_test_score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results'"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "param = {'min_samples_split':np.arange(0.076,0.079,0.0002),'min_samples_leaf' : np.arange(0.001,0.002,0.0001)}\n",
    "\n",
    "clf = GridSearchCV(model,param,cv = 5,return_train_score= True)\n",
    "clf.fit(X,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.888092</td>\n",
       "      <td>0.064037</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.079</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.927170</td>\n",
       "      <td>0.078055</td>\n",
       "      <td>0.018142</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1.900152</td>\n",
       "      <td>0.113813</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.076</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1.987203</td>\n",
       "      <td>0.068023</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.907071</td>\n",
       "      <td>0.071390</td>\n",
       "      <td>0.017924</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.912580</td>\n",
       "      <td>0.090939</td>\n",
       "      <td>0.018742</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.924420</td>\n",
       "      <td>0.081259</td>\n",
       "      <td>0.018309</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.077</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.977210</td>\n",
       "      <td>0.094127</td>\n",
       "      <td>0.018613</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.949287</td>\n",
       "      <td>0.069328</td>\n",
       "      <td>0.018173</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1.916546</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.018171</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1.914577</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1.910944</td>\n",
       "      <td>0.075359</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.078</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1.910904</td>\n",
       "      <td>0.059991</td>\n",
       "      <td>0.018356</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1.916473</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.901626</td>\n",
       "      <td>0.067520</td>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1.914138</td>\n",
       "      <td>0.094333</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>{'min_samples_leaf': 0.0019000000000000004, 'm...</td>\n",
       "      <td>0.565610</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561956</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563651</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.563997</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563950</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.917761</td>\n",
       "      <td>0.080518</td>\n",
       "      <td>0.018167</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.901135</td>\n",
       "      <td>0.083662</td>\n",
       "      <td>0.018039</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.897151</td>\n",
       "      <td>0.083864</td>\n",
       "      <td>0.018459</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.076</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.908957</td>\n",
       "      <td>0.073787</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.079</td>\n",
       "      <td>{'min_samples_leaf': 0.0012000000000000001, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.905566</td>\n",
       "      <td>0.074811</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>{'min_samples_leaf': 0.0012000000000000001, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.907598</td>\n",
       "      <td>0.072759</td>\n",
       "      <td>0.018206</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>{'min_samples_leaf': 0.0012000000000000001, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.926321</td>\n",
       "      <td>0.096021</td>\n",
       "      <td>0.018124</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>{'min_samples_leaf': 0.0012000000000000001, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.929674</td>\n",
       "      <td>0.093346</td>\n",
       "      <td>0.018622</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.078</td>\n",
       "      <td>{'min_samples_leaf': 0.0012000000000000001, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.883894</td>\n",
       "      <td>0.081611</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.913036</td>\n",
       "      <td>0.098903</td>\n",
       "      <td>0.018503</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>{'min_samples_leaf': 0.0012000000000000001, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.921572</td>\n",
       "      <td>0.094032</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.925773</td>\n",
       "      <td>0.076031</td>\n",
       "      <td>0.017863</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.908620</td>\n",
       "      <td>0.097984</td>\n",
       "      <td>0.018514</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.898246</td>\n",
       "      <td>0.091428</td>\n",
       "      <td>0.018505</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.939461</td>\n",
       "      <td>0.071560</td>\n",
       "      <td>0.018329</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.909699</td>\n",
       "      <td>0.071479</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.926290</td>\n",
       "      <td>0.077557</td>\n",
       "      <td>0.017930</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.078</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.878402</td>\n",
       "      <td>0.069897</td>\n",
       "      <td>0.018304</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.913611</td>\n",
       "      <td>0.091459</td>\n",
       "      <td>0.019110</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>{'min_samples_leaf': 0.0012000000000000001, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.891334</td>\n",
       "      <td>0.058838</td>\n",
       "      <td>0.018035</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.927740</td>\n",
       "      <td>0.078501</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.898332</td>\n",
       "      <td>0.079884</td>\n",
       "      <td>0.018097</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.079</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.901408</td>\n",
       "      <td>0.051653</td>\n",
       "      <td>0.018794</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.077</td>\n",
       "      <td>{'min_samples_leaf': 0.0013000000000000002, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.932448</td>\n",
       "      <td>0.109131</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>{'min_samples_leaf': 0.0012000000000000001, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.935238</td>\n",
       "      <td>0.138807</td>\n",
       "      <td>0.018620</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.076</td>\n",
       "      <td>{'min_samples_leaf': 0.001, 'min_samples_split...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.936374</td>\n",
       "      <td>0.095671</td>\n",
       "      <td>0.018719</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>{'min_samples_leaf': 0.0012000000000000001, 'm...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.942446</td>\n",
       "      <td>0.128718</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.076</td>\n",
       "      <td>{'min_samples_leaf': 0.0011, 'min_samples_spli...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.938603</td>\n",
       "      <td>0.051127</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>{'min_samples_leaf': 0.001, 'min_samples_split...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.940978</td>\n",
       "      <td>0.084429</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>{'min_samples_leaf': 0.001, 'min_samples_split...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.938149</td>\n",
       "      <td>0.066116</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>{'min_samples_leaf': 0.001, 'min_samples_split...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.955005</td>\n",
       "      <td>0.121433</td>\n",
       "      <td>0.018044</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>{'min_samples_leaf': 0.001, 'min_samples_split...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.942996</td>\n",
       "      <td>0.058982</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.077</td>\n",
       "      <td>{'min_samples_leaf': 0.001, 'min_samples_split...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.928024</td>\n",
       "      <td>0.107893</td>\n",
       "      <td>0.018210</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>{'min_samples_leaf': 0.001, 'min_samples_split...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.933101</td>\n",
       "      <td>0.092294</td>\n",
       "      <td>0.018495</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>{'min_samples_leaf': 0.0011, 'min_samples_spli...</td>\n",
       "      <td>0.565404</td>\n",
       "      <td>0.558654</td>\n",
       "      <td>0.560935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561919</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.563572</td>\n",
       "      <td>0.563787</td>\n",
       "      <td>0.564035</td>\n",
       "      <td>0.563927</td>\n",
       "      <td>0.56439</td>\n",
       "      <td>0.563942</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "159       1.888092      0.064037         0.018116        0.000328   \n",
       "158       1.927170      0.078055         0.018142        0.000175   \n",
       "144       1.900152      0.113813         0.018509        0.000909   \n",
       "146       1.987203      0.068023         0.018408        0.000418   \n",
       "147       1.907071      0.071390         0.017924        0.000335   \n",
       "148       1.912580      0.090939         0.018742        0.000941   \n",
       "149       1.924420      0.081259         0.018309        0.000393   \n",
       "150       1.977210      0.094127         0.018613        0.000473   \n",
       "145       1.949287      0.069328         0.018173        0.000253   \n",
       "152       1.916546      0.043200         0.018171        0.000072   \n",
       "153       1.914577      0.043300         0.018397        0.000851   \n",
       "154       1.910944      0.075359         0.018667        0.000585   \n",
       "155       1.910904      0.059991         0.018356        0.000967   \n",
       "156       1.916473      0.057000         0.018284        0.000265   \n",
       "157       1.901626      0.067520         0.018186        0.000282   \n",
       "151       1.914138      0.094333         0.018120        0.000530   \n",
       "50        1.917761      0.080518         0.018167        0.000781   \n",
       "49        1.901135      0.083662         0.018039        0.000272   \n",
       "48        1.897151      0.083864         0.018459        0.000610   \n",
       "47        1.908957      0.073787         0.018181        0.000198   \n",
       "43        1.905566      0.074811         0.018431        0.000889   \n",
       "45        1.907598      0.072759         0.018206        0.000803   \n",
       "44        1.926321      0.096021         0.018124        0.000291   \n",
       "42        1.929674      0.093346         0.018622        0.000449   \n",
       "51        1.883894      0.081611         0.019097        0.001062   \n",
       "46        1.913036      0.098903         0.018503        0.000750   \n",
       "52        1.921572      0.094032         0.018097        0.000572   \n",
       "60        1.925773      0.076031         0.017863        0.000376   \n",
       "54        1.908620      0.097984         0.018514        0.000691   \n",
       "55        1.898246      0.091428         0.018505        0.001299   \n",
       "56        1.939461      0.071560         0.018329        0.000475   \n",
       "57        1.909699      0.071479         0.017943        0.000277   \n",
       "58        1.926290      0.077557         0.017930        0.000332   \n",
       "59        1.878402      0.069897         0.018304        0.000545   \n",
       "41        1.913611      0.091459         0.019110        0.001179   \n",
       "61        1.891334      0.058838         0.018035        0.000484   \n",
       "62        1.927740      0.078501         0.018775        0.001128   \n",
       "63        1.898332      0.079884         0.018097        0.000732   \n",
       "53        1.901408      0.051653         0.018794        0.001583   \n",
       "40        1.932448      0.109131         0.018421        0.000190   \n",
       "0         1.935238      0.138807         0.018620        0.000715   \n",
       "38        1.936374      0.095671         0.018719        0.001419   \n",
       "16        1.942446      0.128718         0.018033        0.000734   \n",
       "1         1.938603      0.051127         0.017851        0.000347   \n",
       "2         1.940978      0.084429         0.017968        0.000259   \n",
       "3         1.938149      0.066116         0.018433        0.000537   \n",
       "4         1.955005      0.121433         0.018044        0.000381   \n",
       "5         1.942996      0.058982         0.017964        0.001026   \n",
       "6         1.928024      0.107893         0.018210        0.000620   \n",
       "17        1.933101      0.092294         0.018495        0.000785   \n",
       "\n",
       "    param_min_samples_leaf param_min_samples_split  \\\n",
       "159                 0.0019                   0.079   \n",
       "158                 0.0019                  0.0788   \n",
       "144                 0.0019                   0.076   \n",
       "146                 0.0019                  0.0764   \n",
       "147                 0.0019                  0.0766   \n",
       "148                 0.0019                  0.0768   \n",
       "149                 0.0019                   0.077   \n",
       "150                 0.0019                  0.0772   \n",
       "145                 0.0019                  0.0762   \n",
       "152                 0.0019                  0.0776   \n",
       "153                 0.0019                  0.0778   \n",
       "154                 0.0019                   0.078   \n",
       "155                 0.0019                  0.0782   \n",
       "156                 0.0019                  0.0784   \n",
       "157                 0.0019                  0.0786   \n",
       "151                 0.0019                  0.0774   \n",
       "50                  0.0013                  0.0764   \n",
       "49                  0.0013                  0.0762   \n",
       "48                  0.0013                   0.076   \n",
       "47                  0.0012                   0.079   \n",
       "43                  0.0012                  0.0782   \n",
       "45                  0.0012                  0.0786   \n",
       "44                  0.0012                  0.0784   \n",
       "42                  0.0012                   0.078   \n",
       "51                  0.0013                  0.0766   \n",
       "46                  0.0012                  0.0788   \n",
       "52                  0.0013                  0.0768   \n",
       "60                  0.0013                  0.0784   \n",
       "54                  0.0013                  0.0772   \n",
       "55                  0.0013                  0.0774   \n",
       "56                  0.0013                  0.0776   \n",
       "57                  0.0013                  0.0778   \n",
       "58                  0.0013                   0.078   \n",
       "59                  0.0013                  0.0782   \n",
       "41                  0.0012                  0.0778   \n",
       "61                  0.0013                  0.0786   \n",
       "62                  0.0013                  0.0788   \n",
       "63                  0.0013                   0.079   \n",
       "53                  0.0013                   0.077   \n",
       "40                  0.0012                  0.0776   \n",
       "0                    0.001                   0.076   \n",
       "38                  0.0012                  0.0772   \n",
       "16                  0.0011                   0.076   \n",
       "1                    0.001                  0.0762   \n",
       "2                    0.001                  0.0764   \n",
       "3                    0.001                  0.0766   \n",
       "4                    0.001                  0.0768   \n",
       "5                    0.001                   0.077   \n",
       "6                    0.001                  0.0772   \n",
       "17                  0.0011                  0.0762   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "159  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "158  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "144  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "146  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "147  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "148  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "149  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "150  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "145  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "152  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "153  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "154  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "155  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "156  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "157  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "151  {'min_samples_leaf': 0.0019000000000000004, 'm...           0.565610   \n",
       "50   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "49   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "48   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "47   {'min_samples_leaf': 0.0012000000000000001, 'm...           0.565404   \n",
       "43   {'min_samples_leaf': 0.0012000000000000001, 'm...           0.565404   \n",
       "45   {'min_samples_leaf': 0.0012000000000000001, 'm...           0.565404   \n",
       "44   {'min_samples_leaf': 0.0012000000000000001, 'm...           0.565404   \n",
       "42   {'min_samples_leaf': 0.0012000000000000001, 'm...           0.565404   \n",
       "51   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "46   {'min_samples_leaf': 0.0012000000000000001, 'm...           0.565404   \n",
       "52   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "60   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "54   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "55   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "56   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "57   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "58   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "59   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "41   {'min_samples_leaf': 0.0012000000000000001, 'm...           0.565404   \n",
       "61   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "62   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "63   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "53   {'min_samples_leaf': 0.0013000000000000002, 'm...           0.565404   \n",
       "40   {'min_samples_leaf': 0.0012000000000000001, 'm...           0.565404   \n",
       "0    {'min_samples_leaf': 0.001, 'min_samples_split...           0.565404   \n",
       "38   {'min_samples_leaf': 0.0012000000000000001, 'm...           0.565404   \n",
       "16   {'min_samples_leaf': 0.0011, 'min_samples_spli...           0.565404   \n",
       "1    {'min_samples_leaf': 0.001, 'min_samples_split...           0.565404   \n",
       "2    {'min_samples_leaf': 0.001, 'min_samples_split...           0.565404   \n",
       "3    {'min_samples_leaf': 0.001, 'min_samples_split...           0.565404   \n",
       "4    {'min_samples_leaf': 0.001, 'min_samples_split...           0.565404   \n",
       "5    {'min_samples_leaf': 0.001, 'min_samples_split...           0.565404   \n",
       "6    {'min_samples_leaf': 0.001, 'min_samples_split...           0.565404   \n",
       "17   {'min_samples_leaf': 0.0011, 'min_samples_spli...           0.565404   \n",
       "\n",
       "     split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "159           0.558654           0.560916  ...         0.561956   \n",
       "158           0.558654           0.560916  ...         0.561956   \n",
       "144           0.558654           0.560916  ...         0.561956   \n",
       "146           0.558654           0.560916  ...         0.561956   \n",
       "147           0.558654           0.560916  ...         0.561956   \n",
       "148           0.558654           0.560916  ...         0.561956   \n",
       "149           0.558654           0.560916  ...         0.561956   \n",
       "150           0.558654           0.560916  ...         0.561956   \n",
       "145           0.558654           0.560916  ...         0.561956   \n",
       "152           0.558654           0.560916  ...         0.561956   \n",
       "153           0.558654           0.560916  ...         0.561956   \n",
       "154           0.558654           0.560916  ...         0.561956   \n",
       "155           0.558654           0.560916  ...         0.561956   \n",
       "156           0.558654           0.560916  ...         0.561956   \n",
       "157           0.558654           0.560916  ...         0.561956   \n",
       "151           0.558654           0.560916  ...         0.561956   \n",
       "50            0.558654           0.560935  ...         0.561919   \n",
       "49            0.558654           0.560935  ...         0.561919   \n",
       "48            0.558654           0.560935  ...         0.561919   \n",
       "47            0.558654           0.560935  ...         0.561919   \n",
       "43            0.558654           0.560935  ...         0.561919   \n",
       "45            0.558654           0.560935  ...         0.561919   \n",
       "44            0.558654           0.560935  ...         0.561919   \n",
       "42            0.558654           0.560935  ...         0.561919   \n",
       "51            0.558654           0.560935  ...         0.561919   \n",
       "46            0.558654           0.560935  ...         0.561919   \n",
       "52            0.558654           0.560935  ...         0.561919   \n",
       "60            0.558654           0.560935  ...         0.561919   \n",
       "54            0.558654           0.560935  ...         0.561919   \n",
       "55            0.558654           0.560935  ...         0.561919   \n",
       "56            0.558654           0.560935  ...         0.561919   \n",
       "57            0.558654           0.560935  ...         0.561919   \n",
       "58            0.558654           0.560935  ...         0.561919   \n",
       "59            0.558654           0.560935  ...         0.561919   \n",
       "41            0.558654           0.560935  ...         0.561919   \n",
       "61            0.558654           0.560935  ...         0.561919   \n",
       "62            0.558654           0.560935  ...         0.561919   \n",
       "63            0.558654           0.560935  ...         0.561919   \n",
       "53            0.558654           0.560935  ...         0.561919   \n",
       "40            0.558654           0.560935  ...         0.561919   \n",
       "0             0.558654           0.560935  ...         0.561919   \n",
       "38            0.558654           0.560935  ...         0.561919   \n",
       "16            0.558654           0.560935  ...         0.561919   \n",
       "1             0.558654           0.560935  ...         0.561919   \n",
       "2             0.558654           0.560935  ...         0.561919   \n",
       "3             0.558654           0.560935  ...         0.561919   \n",
       "4             0.558654           0.560935  ...         0.561919   \n",
       "5             0.558654           0.560935  ...         0.561919   \n",
       "6             0.558654           0.560935  ...         0.561919   \n",
       "17            0.558654           0.560935  ...         0.561919   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "159        0.002262                1            0.563651            0.563787   \n",
       "158        0.002262                1            0.563651            0.563787   \n",
       "144        0.002262                1            0.563651            0.563787   \n",
       "146        0.002262                1            0.563651            0.563787   \n",
       "147        0.002262                1            0.563651            0.563787   \n",
       "148        0.002262                1            0.563651            0.563787   \n",
       "149        0.002262                1            0.563651            0.563787   \n",
       "150        0.002262                1            0.563651            0.563787   \n",
       "145        0.002262                1            0.563651            0.563787   \n",
       "152        0.002262                1            0.563651            0.563787   \n",
       "153        0.002262                1            0.563651            0.563787   \n",
       "154        0.002262                1            0.563651            0.563787   \n",
       "155        0.002262                1            0.563651            0.563787   \n",
       "156        0.002262                1            0.563651            0.563787   \n",
       "157        0.002262                1            0.563651            0.563787   \n",
       "151        0.002262                1            0.563651            0.563787   \n",
       "50         0.002195               17            0.563572            0.563787   \n",
       "49         0.002195               17            0.563572            0.563787   \n",
       "48         0.002195               17            0.563572            0.563787   \n",
       "47         0.002195               17            0.563572            0.563787   \n",
       "43         0.002195               17            0.563572            0.563787   \n",
       "45         0.002195               17            0.563572            0.563787   \n",
       "44         0.002195               17            0.563572            0.563787   \n",
       "42         0.002195               17            0.563572            0.563787   \n",
       "51         0.002195               17            0.563572            0.563787   \n",
       "46         0.002195               17            0.563572            0.563787   \n",
       "52         0.002195               17            0.563572            0.563787   \n",
       "60         0.002195               17            0.563572            0.563787   \n",
       "54         0.002195               17            0.563572            0.563787   \n",
       "55         0.002195               17            0.563572            0.563787   \n",
       "56         0.002195               17            0.563572            0.563787   \n",
       "57         0.002195               17            0.563572            0.563787   \n",
       "58         0.002195               17            0.563572            0.563787   \n",
       "59         0.002195               17            0.563572            0.563787   \n",
       "41         0.002195               17            0.563572            0.563787   \n",
       "61         0.002195               17            0.563572            0.563787   \n",
       "62         0.002195               17            0.563572            0.563787   \n",
       "63         0.002195               17            0.563572            0.563787   \n",
       "53         0.002195               17            0.563572            0.563787   \n",
       "40         0.002195               17            0.563572            0.563787   \n",
       "0          0.002195               17            0.563572            0.563787   \n",
       "38         0.002195               17            0.563572            0.563787   \n",
       "16         0.002195               17            0.563572            0.563787   \n",
       "1          0.002195               17            0.563572            0.563787   \n",
       "2          0.002195               17            0.563572            0.563787   \n",
       "3          0.002195               17            0.563572            0.563787   \n",
       "4          0.002195               17            0.563572            0.563787   \n",
       "5          0.002195               17            0.563572            0.563787   \n",
       "6          0.002195               17            0.563572            0.563787   \n",
       "17         0.002195               17            0.563572            0.563787   \n",
       "\n",
       "     split2_train_score  split3_train_score  split4_train_score  \\\n",
       "159            0.563997            0.563927             0.56439   \n",
       "158            0.563997            0.563927             0.56439   \n",
       "144            0.563997            0.563927             0.56439   \n",
       "146            0.563997            0.563927             0.56439   \n",
       "147            0.563997            0.563927             0.56439   \n",
       "148            0.563997            0.563927             0.56439   \n",
       "149            0.563997            0.563927             0.56439   \n",
       "150            0.563997            0.563927             0.56439   \n",
       "145            0.563997            0.563927             0.56439   \n",
       "152            0.563997            0.563927             0.56439   \n",
       "153            0.563997            0.563927             0.56439   \n",
       "154            0.563997            0.563927             0.56439   \n",
       "155            0.563997            0.563927             0.56439   \n",
       "156            0.563997            0.563927             0.56439   \n",
       "157            0.563997            0.563927             0.56439   \n",
       "151            0.563997            0.563927             0.56439   \n",
       "50             0.564035            0.563927             0.56439   \n",
       "49             0.564035            0.563927             0.56439   \n",
       "48             0.564035            0.563927             0.56439   \n",
       "47             0.564035            0.563927             0.56439   \n",
       "43             0.564035            0.563927             0.56439   \n",
       "45             0.564035            0.563927             0.56439   \n",
       "44             0.564035            0.563927             0.56439   \n",
       "42             0.564035            0.563927             0.56439   \n",
       "51             0.564035            0.563927             0.56439   \n",
       "46             0.564035            0.563927             0.56439   \n",
       "52             0.564035            0.563927             0.56439   \n",
       "60             0.564035            0.563927             0.56439   \n",
       "54             0.564035            0.563927             0.56439   \n",
       "55             0.564035            0.563927             0.56439   \n",
       "56             0.564035            0.563927             0.56439   \n",
       "57             0.564035            0.563927             0.56439   \n",
       "58             0.564035            0.563927             0.56439   \n",
       "59             0.564035            0.563927             0.56439   \n",
       "41             0.564035            0.563927             0.56439   \n",
       "61             0.564035            0.563927             0.56439   \n",
       "62             0.564035            0.563927             0.56439   \n",
       "63             0.564035            0.563927             0.56439   \n",
       "53             0.564035            0.563927             0.56439   \n",
       "40             0.564035            0.563927             0.56439   \n",
       "0              0.564035            0.563927             0.56439   \n",
       "38             0.564035            0.563927             0.56439   \n",
       "16             0.564035            0.563927             0.56439   \n",
       "1              0.564035            0.563927             0.56439   \n",
       "2              0.564035            0.563927             0.56439   \n",
       "3              0.564035            0.563927             0.56439   \n",
       "4              0.564035            0.563927             0.56439   \n",
       "5              0.564035            0.563927             0.56439   \n",
       "6              0.564035            0.563927             0.56439   \n",
       "17             0.564035            0.563927             0.56439   \n",
       "\n",
       "     mean_train_score  std_train_score  \n",
       "159          0.563950         0.000250  \n",
       "158          0.563950         0.000250  \n",
       "144          0.563950         0.000250  \n",
       "146          0.563950         0.000250  \n",
       "147          0.563950         0.000250  \n",
       "148          0.563950         0.000250  \n",
       "149          0.563950         0.000250  \n",
       "150          0.563950         0.000250  \n",
       "145          0.563950         0.000250  \n",
       "152          0.563950         0.000250  \n",
       "153          0.563950         0.000250  \n",
       "154          0.563950         0.000250  \n",
       "155          0.563950         0.000250  \n",
       "156          0.563950         0.000250  \n",
       "157          0.563950         0.000250  \n",
       "151          0.563950         0.000250  \n",
       "50           0.563942         0.000272  \n",
       "49           0.563942         0.000272  \n",
       "48           0.563942         0.000272  \n",
       "47           0.563942         0.000272  \n",
       "43           0.563942         0.000272  \n",
       "45           0.563942         0.000272  \n",
       "44           0.563942         0.000272  \n",
       "42           0.563942         0.000272  \n",
       "51           0.563942         0.000272  \n",
       "46           0.563942         0.000272  \n",
       "52           0.563942         0.000272  \n",
       "60           0.563942         0.000272  \n",
       "54           0.563942         0.000272  \n",
       "55           0.563942         0.000272  \n",
       "56           0.563942         0.000272  \n",
       "57           0.563942         0.000272  \n",
       "58           0.563942         0.000272  \n",
       "59           0.563942         0.000272  \n",
       "41           0.563942         0.000272  \n",
       "61           0.563942         0.000272  \n",
       "62           0.563942         0.000272  \n",
       "63           0.563942         0.000272  \n",
       "53           0.563942         0.000272  \n",
       "40           0.563942         0.000272  \n",
       "0            0.563942         0.000272  \n",
       "38           0.563942         0.000272  \n",
       "16           0.563942         0.000272  \n",
       "1            0.563942         0.000272  \n",
       "2            0.563942         0.000272  \n",
       "3            0.563942         0.000272  \n",
       "4            0.563942         0.000272  \n",
       "5            0.563942         0.000272  \n",
       "6            0.563942         0.000272  \n",
       "17           0.563942         0.000272  \n",
       "\n",
       "[50 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_).sort_values(by='rank_test_score').head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0.07900000000000008 leaf 0.0019000000000000004\n",
      "avg_train_f1_score: 0.6253566040106506\n",
      "avg_test_f1_score: 0.6237189978778426\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = KFold(n_splits = 5)\n",
    "total_train = 0\n",
    "total_test = 0\n",
    "for train_index, test_index in kfold.split(X,y):\n",
    "    x_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    x_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    model = DecisionTreeClassifier(min_samples_split = 0.0774, min_samples_leaf =0.0019)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    total_train += f1_score(y_train,model.predict(x_train))\n",
    "    total_test += f1_score(y_test, model.predict(x_test))\n",
    "print('split',split,'leaf',leaf)\n",
    "print('avg_train_f1_score:',total_train/5)\n",
    "print('avg_test_f1_score:',total_test/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng\n",
      "split 0.0001 leaf 0.0001\n",
      "avg_train_f1_score: 0.6910084068832054\n",
      "avg_test_f1_score: 0.6005734839981496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv('train_small.csv')\n",
    "predictor = MyPredictor(True, False, 1)\n",
    "df_X, df_y = predictor.fit_preprocessing(df)\n",
    "predictor.fit_transformer(df_X)\n",
    "\n",
    "X = predictor.transform(df_X)\n",
    "y = df_y\n",
    "\n",
    "kfold = KFold(n_splits = 5)\n",
    "total_train = 0\n",
    "total_test = 0\n",
    "for train_index, test_index in kfold.split(X,y):\n",
    "    x_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    x_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    model_rfc = RandomForestClassifier(max_features = 'sqrt')\n",
    "    model_rfc.fit(x_train, y_train)\n",
    "\n",
    "    total_train += f1_score(y_train,model_rfc.predict(x_train))\n",
    "    total_test += f1_score(y_test, model_rfc.predict(x_test))\n",
    "\n",
    "print('avg_train_f1_score:',total_train/5)\n",
    "print('avg_test_f1_score:',total_test/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 0.0001 leaf 0.0001\n",
      "avg_train_f1_score: 0.9988658101507666\n",
      "avg_test_f1_score: 0.6048132380536039\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train_small.csv')\n",
    "predictor = MyPredictor(False, False, 1)\n",
    "df_X, df_y = predictor.fit_preprocessing(df)\n",
    "predictor.fit_transformer(df_X)\n",
    "\n",
    "X = predictor.transform(df_X)\n",
    "y = df_y\n",
    "\n",
    "kfold = KFold(n_splits = 5)\n",
    "total_train = 0\n",
    "total_test = 0\n",
    "for train_index, test_index in kfold.split(X,y):\n",
    "    x_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    x_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    model_rfc = RandomForestClassifier(max_features = 'sqrt')\n",
    "    model_rfc.fit(x_train, y_train)\n",
    "\n",
    "    total_train += f1_score(y_train,model_rfc.predict(x_train))\n",
    "    total_test += f1_score(y_test, model_rfc.predict(x_test))\n",
    "\n",
    "print('avg_train_f1_score:',total_train/5)\n",
    "print('avg_test_f1_score:',total_test/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng\n",
      "clean_rows\n",
      "e ['Platform', 'Census_OSArchitecture', 'SkuEdition', 'OsBuildLab1', 'Census_ActivationChannel', 'Census_OSInstallTypeName', 'Census_GenuineStateName', 'Census_DeviceFamily', 'Census_OSSkuName1', 'Census_ChassisTypeName1', 'Census_PrimaryDiskTypeName', 'Census_FlightRing', 'Processor', 'Census_MDC2FormFactor', 'Census_OSBranch', 'ProductName', 'Census_OSEdition1', 'SmartScreen', 'Census_PowerPlatformRoleName', 'Census_InternalBatteryType1', 'OsVer', 'Census_OSWUAutoUpdateOptionsName', 'OsPlatformSubRelease']\n",
      "s ['Census_OSVersion4', 'EngineVersion4', 'IsSxsPassiveMode', 'Census_InternalPrimaryDisplayResolutionHorizontal', 'Census_InternalBatteryNumberOfCharges', 'AvSigVersion3', 'AVProductsEnabled', 'Census_OSBuildNumber', 'LocaleEnglishNameIdentifier', 'OsSuite', 'Census_OSVersion3', 'Census_TotalPhysicalRAM', 'Census_OSBuildRevision', 'AutoSampleOptIn', 'RtpStateBitfield', 'Census_IsPenCapable', 'CountryIdentifier', 'AVProductsInstalled', 'Census_IsAlwaysOnAlwaysConnectedCapable', 'Census_ProcessorCoreCount', 'AppVersion3', 'AppVersion4', 'UacLuaenable', 'IsProtected', 'Census_IsFlightsDisabled', 'AppVersion2', 'EngineVersion3', 'Census_InternalPrimaryDiagonalDisplaySizeInInches', 'Census_IsVirtualDevice', 'Census_ThresholdOptIn', 'SMode', 'OsBuild', 'Wdft_IsGamer', 'Census_OSUILocaleIdentifier', 'Census_SystemVolumeTotalCapacity', 'IsBeta', 'AvSigVersion2', 'Census_InternalPrimaryDisplayResolutionVertical', 'Census_IsPortableOperatingSystem']\n",
      "n []\n",
      "i ['AVProductStatesIdentifier', 'CityIdentifier', 'OrganizationIdentifier', 'GeoNameIdentifier', 'IeVerIdentifier', 'Census_OEMNameIdentifier', 'Census_OEMModelIdentifier', 'Census_ProcessorManufacturerIdentifier', 'Census_ProcessorModelIdentifier', 'Census_OSInstallLanguageIdentifier', 'Census_FirmwareManufacturerIdentifier', 'Census_FirmwareVersionIdentifier', 'Wdft_RegionIdentifier']\n",
      "ig ['HasDetections', 'MachineIdentifier', 'HasTpm', 'Firewall', 'Census_HasOpticalDiskDrive', 'Census_PrimaryDiskTotalCapacity', 'Census_IsSecureBootEnabled', 'Census_IsWIMBootEnabled', 'Census_IsTouchEnabled', 'EngineVersion1', 'EngineVersion2', 'AppVersion1', 'AvSigVersion4', 'AvSigVersion1', 'Census_OSVersion1', 'Census_OSVersion2', 'EngineVersion', 'AppVersion', 'AvSigVersion', 'Census_OSVersion', 'OsBuildLab', 'Census_ChassisTypeName', 'Census_InternalBatteryType', 'Census_OSEdition', 'Census_OSSkuName', 'DefaultBrowsersIdentifier', 'PuaMode', 'Census_ProcessorClass', 'Census_IsFlightingInternal']\n",
      "train_f1_score: 0.7042669295452955\n",
      "test_f1_score: 0.645308468068662\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('train_small.csv')\n",
    "predictor = MyPredictor(True, True, 0.7)\n",
    "df_X, df_y = predictor.fit_preprocessing(df)\n",
    "X = predictor.le_fit_transform(df_X)\n",
    "y = df_y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)\n",
    "\n",
    "\n",
    "\n",
    "model_rfc = RandomForestClassifier(min_samples_split=210,max_features = 'log2',criterion = 'entropy')\n",
    "model_rfc.fit(X_train, y_train)\n",
    "\n",
    "print('train_f1_score:',f1_score(y_train,model_rfc.predict(X_train)))\n",
    "print('test_f1_score:',f1_score(y_test, model_rfc.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_train_f1_score: 0.999724442119882\n",
    "# avg_test_f1_score: 0.6192692992710961\n",
    "\n",
    "#model_rfc = RandomForestClassifier(min_samples_split=100, max_features = 'log2',criterion = 'entropy')\n",
    "# train_f1_score: 0.7257340824173731\n",
    "# test_f1_score: 0.6312680626679511\n",
    "\n",
    "# labelencoder, RandomForestClassifier(min_samples_split=100,max_features = 'log2',criterion = 'entropy')\n",
    "# train_f1_score: 0.7487606433301798\n",
    "# test_f1_score: 0.6431783921163118\n",
    "\n",
    "# categorical_cols set < 50\n",
    "# test: around 0.64\n",
    "\n",
    "# train_csv\n",
    "# train_f1_score: 0.6914845688688728\n",
    "# test_f1_score: 0.6513570172458772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame({\"Person\":\n",
    "                   [\"John\", \"Myla\", 'Amy', \"John\", \"Myla\"],\n",
    "                   \"Age\": [24., 5, 21., 33, 26],\n",
    "                  \"Single\": [False, True, True, True, False]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>Age</th>\n",
       "      <th>Single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Person  Age  Single\n",
       "0       1    2       0\n",
       "1       2    0       1\n",
       "2       0    1       1\n",
       "3       1    4       1\n",
       "4       2    3       0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "_df.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
