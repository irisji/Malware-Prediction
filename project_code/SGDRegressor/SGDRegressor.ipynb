{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train_small.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 1.63, NNZs: 853, Bias: -0.003503, T: 200531, Avg. loss: 0.309200\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.80, NNZs: 853, Bias: -0.031966, T: 401062, Avg. loss: 0.310737\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.93, NNZs: 853, Bias: -0.024881, T: 601593, Avg. loss: 0.309733\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.96, NNZs: 853, Bias: -0.021887, T: 802124, Avg. loss: 0.309289\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.01, NNZs: 853, Bias: -0.004843, T: 1002655, Avg. loss: 0.309157\n",
      "Total training time: 2.61 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.01, NNZs: 853, Bias: -0.011099, T: 1203186, Avg. loss: 0.309972\n",
      "Total training time: 3.13 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.63, NNZs: 853, Bias: -0.014539, T: 1403717, Avg. loss: 0.127548\n",
      "Total training time: 3.65 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.62, NNZs: 853, Bias: -0.021357, T: 1604248, Avg. loss: 0.126615\n",
      "Total training time: 4.17 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.62, NNZs: 853, Bias: -0.021241, T: 1804779, Avg. loss: 0.126648\n",
      "Total training time: 4.69 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.61, NNZs: 853, Bias: -0.021305, T: 2005310, Avg. loss: 0.126761\n",
      "Total training time: 5.21 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 1.61, NNZs: 853, Bias: -0.021837, T: 2205841, Avg. loss: 0.126440\n",
      "Total training time: 5.73 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 1.61, NNZs: 853, Bias: -0.024008, T: 2406372, Avg. loss: 0.126586\n",
      "Total training time: 6.26 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 1.59, NNZs: 853, Bias: -0.022430, T: 2606903, Avg. loss: 0.114250\n",
      "Total training time: 6.79 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 1.59, NNZs: 853, Bias: -0.022064, T: 2807434, Avg. loss: 0.114140\n",
      "Total training time: 7.31 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 1.59, NNZs: 853, Bias: -0.021689, T: 3007965, Avg. loss: 0.114165\n",
      "Total training time: 7.85 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 1.59, NNZs: 853, Bias: -0.023083, T: 3208496, Avg. loss: 0.114105\n",
      "Total training time: 8.35 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.022788, T: 3409027, Avg. loss: 0.114036\n",
      "Total training time: 8.88 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023073, T: 3609558, Avg. loss: 0.114111\n",
      "Total training time: 9.40 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023218, T: 3810089, Avg. loss: 0.111952\n",
      "Total training time: 9.92 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.022876, T: 4010620, Avg. loss: 0.111827\n",
      "Total training time: 10.43 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023004, T: 4211151, Avg. loss: 0.111892\n",
      "Total training time: 10.96 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023354, T: 4411682, Avg. loss: 0.111839\n",
      "Total training time: 11.48 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.022823, T: 4612213, Avg. loss: 0.111851\n",
      "Total training time: 12.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023113, T: 4812744, Avg. loss: 0.111852\n",
      "Total training time: 12.52 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023110, T: 5013275, Avg. loss: 0.111410\n",
      "Total training time: 13.05 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023091, T: 5213806, Avg. loss: 0.111381\n",
      "Total training time: 13.57 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023072, T: 5414337, Avg. loss: 0.111389\n",
      "Total training time: 14.09 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023126, T: 5614868, Avg. loss: 0.111383\n",
      "Total training time: 14.61 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023020, T: 5815399, Avg. loss: 0.111386\n",
      "Total training time: 15.13 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023127, T: 6015930, Avg. loss: 0.111281\n",
      "Total training time: 15.65 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023020, T: 6216461, Avg. loss: 0.111275\n",
      "Total training time: 16.17 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023087, T: 6416992, Avg. loss: 0.111276\n",
      "Total training time: 16.69 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.022957, T: 6617523, Avg. loss: 0.111274\n",
      "Total training time: 17.20 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023124, T: 6818054, Avg. loss: 0.111275\n",
      "Total training time: 17.73 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023141, T: 7018585, Avg. loss: 0.111252\n",
      "Total training time: 18.24 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023118, T: 7219116, Avg. loss: 0.111249\n",
      "Total training time: 18.76 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023110, T: 7419647, Avg. loss: 0.111250\n",
      "Total training time: 19.27 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023171, T: 7620178, Avg. loss: 0.111251\n",
      "Total training time: 19.80 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 1.58, NNZs: 853, Bias: -0.023154, T: 7820709, Avg. loss: 0.111251\n",
      "Total training time: 20.31 seconds.\n",
      "Convergence after 39 epochs took 20.31 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "class MyPredictor:\n",
    "    def __init__(self, df):\n",
    "        self.ignore = ['RtpStateBitfield', 'HasDetections']\n",
    "        self.categoric_cols = []\n",
    "        self.numeric_cols = []\n",
    "        self.others = []\n",
    "        self.modes = {}\n",
    "        self.means = {}\n",
    "        \n",
    "        self.std = None\n",
    "        self.enc = None\n",
    "        \n",
    "        describe_df = df.describe(include='all')\n",
    "        total = len(df)\n",
    "        describe_df = pd.DataFrame()\n",
    "        describe_df['count'] = df.count()\n",
    "        describe_df['uniques'] = df.nunique()\n",
    "        describe_df['dtype'] = df.dtypes\n",
    "        describe_df['missing'] = 1 - df.count() / total\n",
    "        describe_df.sort_values(by='missing', ascending=False).head(20)\n",
    "        describe_df.apply(lambda x: self.groupCols(x), axis=1)\n",
    "\n",
    "        \n",
    "        #df = self.transformX1(df)\n",
    "        \n",
    "        for cat in self.categoric_cols:\n",
    "            self.modes[cat] = df[cat].mode()[0]\n",
    "        for num in self.numeric_cols:\n",
    "            self.means[num] = df[cat].mean()\n",
    "        \n",
    "        self.enc_cols = list(self.categoric_cols)\n",
    "        self.std_cols = list(self.numeric_cols)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        # df = df.dropna()\n",
    "        self.enc.fit(np.hstack([df[col].fillna(self.modes[col]).values.reshape(len(df), 1) for col in self.categoric_cols]))\n",
    "        #self.enc.fit(df[self.enc_cols])\n",
    "        self.pca = PCA(n_components=20)\n",
    "        self.pca.fit(self.enc.transform(np.hstack([df[col].fillna(self.modes[col]).values.reshape(len(df), 1) for col in self.categoric_cols])).todense())\n",
    "        self.std = MinMaxScaler()\n",
    "        self.std.fit(df[self.std_cols])\n",
    "    \n",
    "    def groupCols(self, x):\n",
    "        if x.name in self.ignore:\n",
    "            return\n",
    "        #if x.missing > 0.8:\n",
    "        #    self.ignore.append(x.name)\n",
    "        if x.uniques < 20:\n",
    "            self.categoric_cols.append(x.name)\n",
    "        elif str(x['dtype']).startswith('int') or str(x['dtype']).startswith('float') and not x.name.endswith('Identifier'):\n",
    "            self.numeric_cols.append(x.name)\n",
    "        else:\n",
    "            self.others.append(x.name)\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        \n",
    "        #X = self.transformX2(df)\n",
    "        #print(df.shape)\n",
    "        #print(X.shape)\n",
    "        #print(df['HasDetections'].shape)\n",
    "        self.linear_model = SGDRegressor(eta0=0.01, verbose=1, learning_rate='adaptive')\n",
    "        self.linear_model.fit(X, y)\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    def transformX2(self, df):\n",
    "        \n",
    "        X1 = self.enc.transform(np.hstack([df[col].fillna(self.modes[col]).values.reshape(len(df), 1) for col in self.categoric_cols]))\n",
    "    \n",
    "        new_df = pd.DataFrame()\n",
    "        for col in self.std_cols:\n",
    "            new_df[col] = df[col].fillna(self.means[col])\n",
    "        X2 = self.std.transform(new_df[self.std_cols])\n",
    "        X3 = self.pca.transform(X1.todense())\n",
    "        X4 = PolynomialFeatures().fit_transform(np.hstack((X3, X2)))\n",
    "        return np.hstack((X1.todense(), X2, X4))\n",
    "    def predict(self, X):\n",
    "        #X = self.transformX1(X)\n",
    "        #X = self.transformX2(X)\n",
    "        y_pred_linear = self.linear_model.predict(X)\n",
    "        return y_pred_linear\n",
    "\n",
    "\n",
    "predictor = MyPredictor(df)\n",
    "\n",
    "X = predictor.transformX2(df)\n",
    "y = df.HasDetections\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "predictor.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_curve, auc\n",
    "\n",
    "fpr_train, tpr_train, threasholds_train = roc_curve(y_train, predictor.predict(X_train))\n",
    "#print(auc(fpr, tpr))\n",
    "fpr_test, tpr_test, threasholds_test = roc_curve(y_test, predictor.predict(X_test))\n",
    "#print(auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6869466038071566\n",
      "0.680577339917421\n"
     ]
    }
   ],
   "source": [
    "print(auc(fpr_train,tpr_train))\n",
    "print(auc(fpr_test,tpr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [fpr_test, tpr_test, threasholds_test, f1_score_test]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [fpr_train, tpr_train, threasholds_train, f1_score_train]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "_df_test = pd.DataFrame({'fpr_test':fpr_test,'tpr_test':tpr_test,'threasholds_test':threasholds_test})\n",
    "_df_train = pd.DataFrame({'fpr_train':fpr_train,'tpr_train':tpr_train,'threasholds_train':threasholds_train})\n",
    "\n",
    "test_p = y_test[y_test ==1]\n",
    "test_n = y_test[y_test ==0]\n",
    "train_p = y_train[y_train ==1]\n",
    "train_n = y_train[y_train ==0]\n",
    "\n",
    "_tp_test = _df_test['tpr_test'] * test_p\n",
    "_fp_test = _df_test['fpr_test'] * test_n\n",
    "_tn_test = test_n - _fp_test\n",
    "_fn_test = test_p - _tp_test\n",
    "\n",
    "_tp_train = _df_train['tpr_train'] * train_p\n",
    "_fp_train = _df_train['fpr_train'] * train_n\n",
    "_tn_train = train_n - _fp_train\n",
    "_fn_train = train_p - _tp_train\n",
    "\n",
    "_df_test['f1_score_test'] = (2*_tp_test)/(2*_tp_test+_fp_test+_fn_test)\n",
    "_df_train['f1_score_train'] = (2*_tp_train)/(2*_tp_train+_fp_train+_fn_train)\n",
    "print(_df_test.loc[_df_test['f1_score_test']==_df_test['f1_score_test'].max(),:])\n",
    "print(_df_train.loc[_df_train['f1_score_train']==_df_train['f1_score_train'].max(),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6749596688944148\n",
      "0.6744443228085389\n"
     ]
    }
   ],
   "source": [
    "# only encoded columns + std numeric columns\n",
    "# train: 0.6749596688944148\n",
    "# test: 0.6744443228085389\n",
    "\n",
    "# only pca encoded columns + std numeric columns\n",
    "# train: 0.6600397599754326\n",
    "# test: 0.653487130380312\n",
    "\n",
    "# only pca columns + std numeric columns + D2 polynomial features\n",
    "# train: 0.6765747359611772\n",
    "# test: 0.6752841944397836\n",
    "\n",
    "# only encode columns + std numeric columns + D2 polynomial features(pca + std numeric)\n",
    "# train: 0.6873718453029778\n",
    "# test: 0.6797208159137644"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
